{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "DATA_PATH = \"../example_data\"\n",
    "GLOVE_PATH = \"/home/yflyl/glove.840B.300d.txt\"\n",
    "MODEL_DIR=\"../../../model_all\"\n",
    "NUM_CITY = 100\n",
    "NUM_TOPIC = 100\n",
    "CITY_EMB_DIM = 50\n",
    "TOPIC_EMB_DIM = 50\n",
    "USER_ID_EMB_DIM = 50\n",
    "GROUP_ID_EMB_DIM = 50\n",
    "DESC_DIM = 100\n",
    "USER_EMB_DIM = 256\n",
    "GROUP_EMB_DIM = 256\n",
    "WORD_EMB_DIM = 300\n",
    "NUM_GROUP_DESC = 200\n",
    "NUM_EVENT_DESC = 200\n",
    "DROP_RATIO = 0.1\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f237bf61b04361b966b2c14281f8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf63b448f24409ab3ac462d2badf659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word dict length: 4\n",
      "Have words: 4\n",
      "Missing rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "# get word dict and word embedding table\n",
    "with open(os.path.join(DATA_PATH, 'word.tsv'), 'r', encoding='utf-8') as f:\n",
    "    word_file = f.readlines()[1:]\n",
    "\n",
    "word_dict = {}\n",
    "for line in tqdm(word_file):\n",
    "    idx, word = line.strip('\\n').split('\\t')\n",
    "    word_dict[word] = int(idx)\n",
    "\n",
    "word_embedding = np.zeros(shape=(len(word_dict) + 1, WORD_EMB_DIM))\n",
    "have_word = 0\n",
    "with open(GLOVE_PATH, 'rb') as f:\n",
    "    for line in tqdm(f):\n",
    "        line = line.split()\n",
    "        word = line[0].decode()\n",
    "        if word in word_dict:\n",
    "            idx = word_dict[word]\n",
    "            tp = [float(x) for x in line[1:]]\n",
    "            word_embedding[idx] = np.array(tp)\n",
    "            have_word += 1\n",
    "word_embedding = torch.from_numpy(word_embedding).float()\n",
    "\n",
    "print(f'Word dict length: {len(word_dict)}')\n",
    "print(f'Have words: {have_word}')\n",
    "print(f'Missing rate: {(len(word_dict) - have_word) / len(word_dict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509bfce17cd540ea941a65d3b1746a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user num: 4\n"
     ]
    }
   ],
   "source": [
    "# get user dict\n",
    "with open(os.path.join(DATA_PATH, 'user.tsv'), 'r', encoding='utf-8') as f:\n",
    "    user_file = f.readlines()[1:]\n",
    "\n",
    "user_dict = {}\n",
    "for line in tqdm(user_file):\n",
    "    idx, topic_list, city = line.strip('\\n').split('\\t')\n",
    "    user_dict[idx] = (eval(topic_list), int(city))\n",
    "\n",
    "NUM_USER = len(user_dict)\n",
    "print(f'Total user num: {NUM_USER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969d26e513cc4effabeadcbe188a7907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total group num: 3\n"
     ]
    }
   ],
   "source": [
    "# get group dict\n",
    "with open(os.path.join(DATA_PATH, 'group.tsv'), 'r', encoding='utf-8') as f:\n",
    "    group_file = f.readlines()[1:]\n",
    "\n",
    "group_dict = {}\n",
    "for line in tqdm(group_file):\n",
    "    idx, topic_list, city, desc = line.strip('\\n').split('\\t')\n",
    "    group_dict[idx] = (eval(topic_list), int(city), eval(desc)[:NUM_GROUP_DESC])\n",
    "\n",
    "NUM_GROUP = len(group_dict)\n",
    "print(f'Total group num: {NUM_GROUP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22acc07de0ca4e21af394c2736aaaa37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a62462edef4db1acf63b7410732305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cce212b2064d0781361585037a9e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94734de10dfa4b038b2e93f2ceebe478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdb07cee0534896868784d5e60df4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of behaviors: [6, 6, 6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "total_time_period = len(os.listdir(os.path.join(DATA_PATH, f'behaviors')))\n",
    "total_behavior, total_user_group, total_user_user = [], [], []\n",
    "\n",
    "for idx in range(total_time_period):\n",
    "    behavior_data = []\n",
    "    with open(os.path.join(DATA_PATH, f'behaviors/{idx}.tsv'), 'r', encoding='utf-8') as f:\n",
    "        behavior_file = f.readlines()[1:]\n",
    "    for line in tqdm(behavior_file):\n",
    "        city, desc, user, group, label = line.strip('\\n').split('\\t')\n",
    "        behavior_data.append((int(city), eval(desc)[:NUM_EVENT_DESC], int(user), int(group), int(label)))\n",
    "    total_behavior.append(behavior_data)\n",
    "    with open(os.path.join(DATA_PATH, f'links/user-group/{idx}.json'), 'r') as f:\n",
    "        user_group_data = json.load(f)\n",
    "        total_user_group.append(torch.FloatTensor(user_group_data))\n",
    "    with open(os.path.join(DATA_PATH, f'links/user-user/{idx}.json'), 'r') as f:\n",
    "        user_user_data = json.load(f)\n",
    "        total_user_user.append(torch.FloatTensor(user_user_data))\n",
    "\n",
    "total_user_group = [torch.zeros((NUM_USER, NUM_GROUP))] + total_user_group[:-1]\n",
    "total_user_user = [torch.zeros((NUM_USER, NUM_USER))] + total_user_user[:-1]\n",
    "\n",
    "for idx in range(1, total_time_period):\n",
    "    total_user_group[idx] += total_user_group[idx - 1]\n",
    "    total_user_user[idx] += total_user_user[idx - 1]\n",
    "\n",
    "print(f'Number of behaviors: {[len(data) for data in total_behavior]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, behavior):\n",
    "        super().__init__()\n",
    "        city, desc, user, group, label = [], [], [], [], []\n",
    "        for t in behavior:\n",
    "            city.append(t[0])\n",
    "            desc.append(t[1])\n",
    "            user.append(t[2])\n",
    "            group.append(t[3])\n",
    "            label.append(t[4])\n",
    "        self.city = np.array(city)\n",
    "        self.desc = np.array(desc)\n",
    "        self.user = np.array(user)\n",
    "        self.group = np.array(group)\n",
    "        self.label = np.array(label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.city[idx], self.desc[idx], self.user[idx], self.group[idx], self.label[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = (y_hat >= 0.5).float()\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.att_fc1 = nn.Linear(emb_size, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, emb_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, emb_dim\n",
    "        \"\"\"\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "        alpha = torch.exp(alpha)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha).squeeze(dim=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, word_embedding):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_embedding, freeze=False)\n",
    "        self.attn = AttentionPooling(WORD_EMB_DIM, WORD_EMB_DIM // 2)\n",
    "        self.dense = nn.Linear(WORD_EMB_DIM // 2, DESC_DIM)\n",
    "        self.dropout = nn.Dropout(p=DROP_RATIO)\n",
    "\n",
    "    def forward(self, text_ids):\n",
    "        '''\n",
    "            input_ids: *, num_words\n",
    "            return: *, DESC_DIM\n",
    "        '''\n",
    "        text_attn_mask = text_ids.ne(0).float()\n",
    "        word_vecs = self.dropout(self.word_embedding(text_ids.long()))\n",
    "        text_vec = self.attn(word_vecs, text_attn_mask)\n",
    "        text_vec = self.dense(text_vec)\n",
    "        return text_vec\n",
    "\n",
    "\n",
    "class TopicEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.topic_embedding = nn.Embedding(NUM_TOPIC, TOPIC_EMB_DIM)\n",
    "        self.attn = AttentionPooling(TOPIC_EMB_DIM, TOPIC_EMB_DIM // 2)\n",
    "\n",
    "    def forward(self, topic_ids):\n",
    "        '''\n",
    "            topic_ids: *, num_topics\n",
    "            return: *, TOPIC_EMB_DIM\n",
    "        '''\n",
    "        topic_attn_mask = topic_ids.ne(0).float()\n",
    "        topic_vec = self.attn(self.topic_embedding(topic_ids), topic_attn_mask)\n",
    "        return topic_vec\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, word_embedding):\n",
    "        super().__init__()\n",
    "        self.city_emb = nn.Embedding(NUM_CITY, CITY_EMB_DIM)\n",
    "        self.user_id_emb = nn.Embedding(NUM_USER, USER_ID_EMB_DIM)\n",
    "        self.group_id_emb = nn.Embedding(NUM_GROUP, GROUP_ID_EMB_DIM)\n",
    "        self.user_emb_linear = nn.Linear(CITY_EMB_DIM + TOPIC_EMB_DIM + USER_ID_EMB_DIM, USER_EMB_DIM)\n",
    "        self.group_emb_linear = nn.Linear(DESC_DIM + TOPIC_EMB_DIM + CITY_EMB_DIM + GROUP_ID_EMB_DIM, GROUP_EMB_DIM)\n",
    "        prediction_dim = USER_EMB_DIM + DESC_DIM + GROUP_EMB_DIM\n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(prediction_dim, prediction_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(prediction_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.text_encoder = TextEncoder(word_embedding)\n",
    "        self.topic_encoder = TopicEncoder()\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "\n",
    "    def update_edge_weight(self, user_group_data, user_user_data):\n",
    "        self.user_group_matrix = user_group_data\n",
    "        self.user_user_matrix = user_user_data\n",
    "\n",
    "    def update_graph(self):\n",
    "        #TODO: Implement GNN Algorithm\n",
    "        user_emb = torch.randn((NUM_USER, USER_EMB_DIM)).to(device)\n",
    "        group_emb = torch.randn((NUM_GROUP, GROUP_EMB_DIM)).to(device)\n",
    "        return user_emb, group_emb\n",
    "\n",
    "    def forward(self, event_city, event_desc, user_id, group_id, label):\n",
    "        '''\n",
    "            event_city: batch_size\n",
    "            event_desc: batch_size, num_words\n",
    "            user_id: batch_size\n",
    "            group_id: batch_size\n",
    "            label: batch_size\n",
    "        '''\n",
    "        user_emb, group_emb = self.update_graph()\n",
    "        batch_city_emb = self.city_emb(event_city)\n",
    "        batch_desc_emb = self.text_encoder(event_desc)\n",
    "        batch_user_emb = torch.index_select(user_emb, dim=0, index=user_id)\n",
    "        batch_group_emb = torch.index_select(group_emb, dim=0, index=group_id)\n",
    "        predict_input = torch.cat([batch_user_emb, batch_city_emb, batch_desc_emb, batch_group_emb], dim=-1)\n",
    "        score = self.prediction(predict_input).squeeze(dim=-1)\n",
    "        loss = self.loss_fn(score, label)\n",
    "        return score, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (city_emb): Embedding(100, 50)\n",
      "  (user_id_emb): Embedding(4, 50)\n",
      "  (group_id_emb): Embedding(3, 50)\n",
      "  (user_emb_linear): Linear(in_features=150, out_features=256, bias=True)\n",
      "  (group_emb_linear): Linear(in_features=250, out_features=256, bias=True)\n",
      "  (prediction): Sequential(\n",
      "    (0): Linear(in_features=612, out_features=306, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=306, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      "  (text_encoder): TextEncoder(\n",
      "    (word_embedding): Embedding(5, 300)\n",
      "    (attn): AttentionPooling(\n",
      "      (att_fc1): Linear(in_features=300, out_features=150, bias=True)\n",
      "      (att_fc2): Linear(in_features=150, out_features=1, bias=True)\n",
      "    )\n",
      "    (dense): Linear(in_features=150, out_features=100, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (topic_encoder): TopicEncoder(\n",
      "    (topic_embedding): Embedding(100, 50)\n",
      "    (attn): AttentionPooling(\n",
      "      (att_fc1): Linear(in_features=50, out_features=25, bias=True)\n",
      "      (att_fc2): Linear(in_features=25, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (loss_fn): BCELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = Model(word_embedding).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(period_idx, mode):\n",
    "    assert mode in ('train', 'val', 'test')\n",
    "    dataset = MyDataset(total_behavior[period_idx])\n",
    "\n",
    "    if mode == 'train':\n",
    "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        model.train()\n",
    "        model.update_edge_weight(total_user_group[period_idx].to(device, non_blocking=True),\n",
    "                                 total_user_user[period_idx].to(device, non_blocking=True))\n",
    "        total_acc, total_loss = 0, 0\n",
    "        for step, (event_city, event_desc, user_id, group_id, label) in enumerate(tqdm(dataloader)):\n",
    "            event_city = event_city.to(device, non_blocking=True)\n",
    "            event_desc = event_desc.to(device, non_blocking=True)\n",
    "            user_id = user_id.to(device, non_blocking=True)\n",
    "            group_id = group_id.to(device, non_blocking=True)\n",
    "            label = label.float().to(device, non_blocking=True)\n",
    "\n",
    "            y_hat, bz_loss = model(event_city, event_desc, user_id, group_id, label)\n",
    "            total_acc += acc(label, y_hat)\n",
    "            total_loss += bz_loss.data.float()\n",
    "            optimizer.zero_grad()\n",
    "            bz_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f'Loss: {total_loss / step}, Acc: {total_acc / step}')\n",
    "\n",
    "        ckpt_path = os.path.join(MODEL_DIR, f'{period_idx}.pt')\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "    else:\n",
    "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.update_edge_weight(total_user_group[period_idx].to(device, non_blocking=True),\n",
    "                                 total_user_user[period_idx].to(device, non_blocking=True))\n",
    "        pred, truth = [], []\n",
    "        for step, (event_city, event_desc, user_id, group_id, label) in enumerate(tqdm(dataloader)):\n",
    "            event_city = event_city.to(device, non_blocking=True)\n",
    "            event_desc = event_desc.to(device, non_blocking=True)\n",
    "            user_id = user_id.to(device, non_blocking=True)\n",
    "            group_id = group_id.to(device, non_blocking=True)\n",
    "            label = label.to(device, non_blocking=True)\n",
    "            \n",
    "            y_hat, _ = model(event_city, event_desc, user_id, group_id, label)\n",
    "            pred.extend(y_hat.to('cpu').detach().numpy())\n",
    "            truth.extent(label.to('cpu').detach().numpy())\n",
    "\n",
    "        print(f'Acc: {acc(truth, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(0, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52c58a27c240379b8b865a3c9db1ed52c803d549678306ff8a2f3c446edaa207"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
